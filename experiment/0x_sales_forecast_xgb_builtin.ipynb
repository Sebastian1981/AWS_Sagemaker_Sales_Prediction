{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NQ05Yg6Dfcq"
   },
   "source": [
    "# TASK #1: UNDERSTAND THE PROBLEM STATEMENT/GOAL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This dataset contains weekly sales from 99 departments belonging to 45 different stores. \n",
    "- Our aim is to forecast weekly sales from a particular department.\n",
    "- The objective of this case study is to forecast weekly retail store sales based on historical data.\n",
    "- The data contains holidays and promotional markdowns offered by various stores and several departments throughout the year.\n",
    "- Markdowns are crucial to promote sales especially before key events such as Super Bowl, Christmas and Thanksgiving. \n",
    "- Developing accurate model will enable make informed decisions and make recommendations to improve business processes in the future. \n",
    "- The data consists of three sheets: \n",
    "    - Stores\n",
    "    - Features\n",
    "    - Sales\n",
    "- Data Source : https://www.kaggle.com/manjeetsingh/retaildataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TprtqAhLn9w8"
   },
   "source": [
    "# TASK #2: IMPORT DATASET AND LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVrKXCk4njhr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>month</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept        Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
       "0      1     1  2010-05-02      24924.50          0        42.31       2.572   \n",
       "1      1     2  2010-05-02      50605.27          0        42.31       2.572   \n",
       "2      1     3  2010-05-02      13740.12          0        42.31       2.572   \n",
       "3      1     4  2010-05-02      39954.04          0        42.31       2.572   \n",
       "4      1     5  2010-05-02      32229.38          0        42.31       2.572   \n",
       "\n",
       "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "1        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "2        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "3        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "4        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "\n",
       "   Unemployment  month Type    Size  \n",
       "0         8.106      5    A  151315  \n",
       "1         8.106      5    A  151315  \n",
       "2         8.106      5    A  151315  \n",
       "3         8.106      5    A  151315  \n",
       "4         8.106      5    A  151315  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data_processed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the date\n",
    "y = df['Weekly_Sales'] # target\n",
    "X = df.drop(columns = ['Weekly_Sales', 'Date']) # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns = ['Type', 'Store', 'Dept'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421570, 138)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421570,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>...</th>\n",
       "      <th>Dept_90</th>\n",
       "      <th>Dept_91</th>\n",
       "      <th>Dept_92</th>\n",
       "      <th>Dept_93</th>\n",
       "      <th>Dept_94</th>\n",
       "      <th>Dept_95</th>\n",
       "      <th>Dept_96</th>\n",
       "      <th>Dept_97</th>\n",
       "      <th>Dept_98</th>\n",
       "      <th>Dept_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsHoliday  Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
       "0          0        42.31       2.572        0.0        0.0        0.0   \n",
       "1          0        42.31       2.572        0.0        0.0        0.0   \n",
       "2          0        42.31       2.572        0.0        0.0        0.0   \n",
       "3          0        42.31       2.572        0.0        0.0        0.0   \n",
       "4          0        42.31       2.572        0.0        0.0        0.0   \n",
       "\n",
       "   MarkDown4  MarkDown5         CPI  Unemployment  ...  Dept_90  Dept_91  \\\n",
       "0        0.0        0.0  211.096358         8.106  ...        0        0   \n",
       "1        0.0        0.0  211.096358         8.106  ...        0        0   \n",
       "2        0.0        0.0  211.096358         8.106  ...        0        0   \n",
       "3        0.0        0.0  211.096358         8.106  ...        0        0   \n",
       "4        0.0        0.0  211.096358         8.106  ...        0        0   \n",
       "\n",
       "   Dept_92  Dept_93  Dept_94  Dept_95  Dept_96  Dept_97  Dept_98  Dept_99  \n",
       "0        0        0        0        0        0        0        0        0  \n",
       "1        0        0        0        0        0        0        0        0  \n",
       "2        0        0        0        0        0        0        0        0  \n",
       "3        0        0        0        0        0        0        0        0  \n",
       "4        0        0        0        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save columnames for later purposes\n",
    "featurenames = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421570, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping the array from (421570,) to (421570, 1)\n",
    "y = y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data into train, validation and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210785, 138)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105393, 138)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105392, 138)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #10: TRAIN XGBOOST USING SAGEMAKER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert the array into dataframe in a way that target variable is set as the first column and followed by feature columns\n",
    "# This is because sagemaker built-in algorithm expects the data in this format.\n",
    "\n",
    "train_data = pd.DataFrame({'Target': y_train[:,0]})\n",
    "for i in range(X_train.shape[1]):\n",
    "    train_data[i] = X_train[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10102.030273</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.220001</td>\n",
       "      <td>3.684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>215.197845</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4424.700195</td>\n",
       "      <td>0.0</td>\n",
       "      <td>57.630001</td>\n",
       "      <td>3.868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>128.910736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3283.199951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.739998</td>\n",
       "      <td>2.642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>209.870880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2362.709961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>54.689999</td>\n",
       "      <td>3.459</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>213.764633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1189.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.770000</td>\n",
       "      <td>3.624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>137.847900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target    0          1      2    3    4    5    6    7           8  \\\n",
       "0  10102.030273  0.0  94.220001  3.684  0.0  0.0  0.0  0.0  0.0  215.197845   \n",
       "1   4424.700195  0.0  57.630001  3.868  0.0  0.0  0.0  0.0  0.0  128.910736   \n",
       "2   3283.199951  0.0  81.739998  2.642  0.0  0.0  0.0  0.0  0.0  209.870880   \n",
       "3   2362.709961  0.0  54.689999  3.459  0.0  0.0  0.0  0.0  0.0  213.764633   \n",
       "4   1189.500000  0.0  38.770000  3.624  0.0  0.0  0.0  0.0  0.0  137.847900   \n",
       "\n",
       "   ...  128  129  130  131  132  133  134  135  136  137  \n",
       "0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "val_data = pd.DataFrame({'Target':y_val[:,0]})\n",
    "for i in range(X_val.shape[1]):\n",
    "    val_data[i] = X_val[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5282.770020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>82.690002</td>\n",
       "      <td>2.940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>136.396271</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1710.479980</td>\n",
       "      <td>0.0</td>\n",
       "      <td>58.900002</td>\n",
       "      <td>2.815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.521866</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20147.779297</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.650002</td>\n",
       "      <td>2.796</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.661606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10652.790039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70.279999</td>\n",
       "      <td>4.254</td>\n",
       "      <td>7299.640137</td>\n",
       "      <td>10818.299805</td>\n",
       "      <td>27.469999</td>\n",
       "      <td>3675.969971</td>\n",
       "      <td>1148.040039</td>\n",
       "      <td>131.108002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6006.850098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.799999</td>\n",
       "      <td>3.413</td>\n",
       "      <td>1003.580017</td>\n",
       "      <td>14.200000</td>\n",
       "      <td>1683.170044</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>570.739990</td>\n",
       "      <td>136.588394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target    0          1      2            3             4  \\\n",
       "0   5282.770020  0.0  82.690002  2.940     0.000000      0.000000   \n",
       "1   1710.479980  0.0  58.900002  2.815     0.000000      0.000000   \n",
       "2  20147.779297  0.0  68.650002  2.796     0.000000      0.000000   \n",
       "3  10652.790039  0.0  70.279999  4.254  7299.640137  10818.299805   \n",
       "4   6006.850098  0.0  27.799999  3.413  1003.580017     14.200000   \n",
       "\n",
       "             5            6            7           8  ...  128  129  130  131  \\\n",
       "0     0.000000     0.000000     0.000000  136.396271  ...  0.0  0.0  0.0  0.0   \n",
       "1     0.000000     0.000000     0.000000  132.521866  ...  0.0  0.0  0.0  0.0   \n",
       "2     0.000000     0.000000     0.000000  132.661606  ...  0.0  0.0  0.0  0.0   \n",
       "3    27.469999  3675.969971  1148.040039  131.108002  ...  0.0  0.0  0.0  0.0   \n",
       "4  1683.170044     2.000000   570.739990  136.588394  ...  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   132  133  134  135  136  137  \n",
       "0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105393, 139)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_data and validation_data as csv files.\n",
    "train_data.to_csv('../data/train.csv', header = False, index = False)\n",
    "val_data.to_csv('../data/validation.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python\n",
    "# Boto3 allows Python developer to write software that makes use of services like Amazon S3 and Amazon EC2\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import Session\n",
    "\n",
    "# Let's create a Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "#bucket = Session().default_bucket() \n",
    "bucket = 'salesprediction-ml-sagemaker'\n",
    "prefix = 'XGBoost-Regressor'\n",
    "key = 'XGBoost-Regressor'\n",
    "#Roles give learning and hosting access to the data\n",
    "#This is specified while opening the sagemakers instance in \"Create an IAM role\"\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::103721820087:role/service-role/AmazonSageMaker-ExecutionRole-20190909T202771\n"
     ]
    }
   ],
   "source": [
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://salesprediction-ml-sagemaker/XGBoost-Regressor/train/XGBoost-Regressor\n"
     ]
    }
   ],
   "source": [
    "# read the data from csv file and then upload the data to s3 bucket\n",
    "import os\n",
    "with open('../data/train.csv','rb') as f:\n",
    "    # The following code uploads the data into S3 bucket to be accessed later for training\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(f)\n",
    "\n",
    "# Let's print out the training data location in s3\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded validation data location: s3://salesprediction-ml-sagemaker/XGBoost-Regressor/validation/XGBoost-Regressor\n"
     ]
    }
   ],
   "source": [
    "# read the data from csv file and then upload the data to s3 bucket\n",
    "\n",
    "with open('../data/validation.csv','rb') as f:\n",
    "    # The following code uploads the data into S3 bucket to be accessed later for training\n",
    "\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation', key)).upload_fileobj(f)\n",
    "# Let's print out the validation data location in s3\n",
    "s3_validation_data = 's3://{}/{}/validation/{}'.format(bucket, prefix, key)\n",
    "print('uploaded validation data location: {}'.format(s3_validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://salesprediction-ml-sagemaker/XGBoost-Regressor/output\n"
     ]
    }
   ],
   "source": [
    "# creates output placeholder in S3 bucket to store the output\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# This code is used to get the training container of sagemaker built-in algorithms\n",
    "# all we have to do is to specify the name of the algorithm, that we want to use\n",
    "\n",
    "# Let's obtain a reference to the XGBoost container image\n",
    "# Note that all regression models are named estimators\n",
    "# You don't have to specify (hardcode) the region, get_image_uri will get the current region name using boto3.Session\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, \n",
    "                          'xgboost',\n",
    "                          #'0.90-2', \n",
    "                          '1.5-1') # Latest version of XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Specify the type of instance that we would like to use for training \n",
    "# output path and sagemaker session into the Estimator. \n",
    "# We can also specify how many instances we would like to use for training\n",
    "\n",
    "# Recall that XGBoost works by combining an ensemble of weak models to generate accurate/robust results. \n",
    "# The weak models are randomized to avoid overfitting\n",
    "\n",
    "# num_round: The number of rounds to run the training.\n",
    "\n",
    "\n",
    "# Alpha: L1 regularization term on weights. Increasing this value makes models more conservative.\n",
    "\n",
    "# colsample_by_tree: fraction of features that will be used to train each tree.\n",
    "\n",
    "# eta: Step size shrinkage used in updates to prevent overfitting. \n",
    "# After each boosting step, eta parameter shrinks the feature weights to make the boosting process more conservative.\n",
    "\n",
    "\n",
    "Xgboost_regressor1 = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count = 1, \n",
    "                                       train_instance_type = 'ml.m5.2xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session)\n",
    "\n",
    "#We can tune the hyper-parameters to improve the performance of the model\n",
    "\n",
    "Xgboost_regressor1.set_hyperparameters(max_depth = 10,\n",
    "                           objective = 'reg:linear',\n",
    "                           colsample_bytree = 0.3,\n",
    "                           alpha = 10,\n",
    "                           eta = 0.1,\n",
    "                           num_round = 100\n",
    "                           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-25 17:04:35 Starting - Starting the training job...\n",
      "2022-11-25 17:04:58 Starting - Preparing the instances for trainingProfilerReport-1669395875: InProgress\n",
      "......\n",
      "2022-11-25 17:05:58 Downloading - Downloading input data...\n",
      "2022-11-25 17:06:18 Training - Downloading the training image...\n",
      "2022-11-25 17:06:58 Training - Training image download completed. Training in progress.\u001b[34m[2022-11-25 17:06:55.188 ip-10-2-218-18.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:55:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:55:INFO] Failed to parse hyperparameter objective value reg:linear to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:55:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:55:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:55:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:55:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:55:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:55:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:56:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:56:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:56:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:56:INFO] Train matrix has 210785 rows and 138 columns\u001b[0m\n",
      "\u001b[34m[2022-11-25:17:06:56:INFO] Validation matrix has 105393 rows\u001b[0m\n",
      "\u001b[34m[2022-11-25 17:06:56.520 ip-10-2-218-18.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[17:06:56] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:26355.12695#011validation-rmse:26588.52148\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:25185.50000#011validation-rmse:25414.96875\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:24344.96875#011validation-rmse:24585.39844\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:23329.86133#011validation-rmse:23597.01758\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:22197.77734#011validation-rmse:22501.89062\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:21509.44336#011validation-rmse:21828.78320\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:20842.86523#011validation-rmse:21149.10742\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:20268.83984#011validation-rmse:20596.62109\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:19680.42969#011validation-rmse:20024.09766\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:19119.56445#011validation-rmse:19433.13477\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:18571.66406#011validation-rmse:18906.24023\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:18215.87891#011validation-rmse:18558.42773\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:17923.53906#011validation-rmse:18274.41211\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:17653.09766#011validation-rmse:18014.43359\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:17495.73242#011validation-rmse:17863.57227\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:17167.44141#011validation-rmse:17539.28906\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:16601.60742#011validation-rmse:16969.06836\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:16445.70117#011validation-rmse:16824.97266\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:16189.03516#011validation-rmse:16582.07227\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:15909.99902#011validation-rmse:16323.85254\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:15742.24414#011validation-rmse:16159.87793\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:15328.45215#011validation-rmse:15769.15039\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:15126.33594#011validation-rmse:15574.86426\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:14970.40527#011validation-rmse:15430.46875\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:14654.47168#011validation-rmse:15116.29297\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:14185.11523#011validation-rmse:14626.06348\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:14005.51367#011validation-rmse:14458.65723\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:13735.47168#011validation-rmse:14185.58789\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:13430.17285#011validation-rmse:13884.17481\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:13195.02637#011validation-rmse:13665.28027\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:12800.39844#011validation-rmse:13274.55273\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:12563.73242#011validation-rmse:13039.60254\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:12424.24316#011validation-rmse:12909.56250\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:12365.49023#011validation-rmse:12852.19629\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:12260.02832#011validation-rmse:12752.47949\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:12056.29297#011validation-rmse:12540.07617\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:11968.46680#011validation-rmse:12455.84766\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:11850.47656#011validation-rmse:12346.89062\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:11662.79394#011validation-rmse:12176.17969\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:11541.28906#011validation-rmse:12062.87500\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:11375.13281#011validation-rmse:11888.11523\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:11194.26562#011validation-rmse:11711.77344\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:10962.88281#011validation-rmse:11492.13672\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:10818.10547#011validation-rmse:11350.88574\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:10777.31641#011validation-rmse:11311.89941\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:10653.54883#011validation-rmse:11209.01074\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:10537.29981#011validation-rmse:11085.49805\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:10485.09082#011validation-rmse:11037.21484\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:10424.23535#011validation-rmse:10978.77539\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:10303.02344#011validation-rmse:10868.19824\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:10056.64356#011validation-rmse:10638.38379\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:9994.79981#011validation-rmse:10581.03320\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:9884.13477#011validation-rmse:10472.36621\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:9811.92383#011validation-rmse:10399.35059\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:9706.58301#011validation-rmse:10307.79004\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:9481.12793#011validation-rmse:10079.72461\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:9432.67871#011validation-rmse:10035.73731\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:9305.59766#011validation-rmse:9916.41406\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:9269.27539#011validation-rmse:9883.71094\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:9228.92676#011validation-rmse:9847.07715\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:9129.91504#011validation-rmse:9759.21777\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:9077.72754#011validation-rmse:9720.27734\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:9009.62500#011validation-rmse:9653.99219\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:8938.84375#011validation-rmse:9590.92676\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:8913.04492#011validation-rmse:9567.01367\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:8864.00684#011validation-rmse:9522.39844\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:8767.63965#011validation-rmse:9445.78027\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:8707.18750#011validation-rmse:9393.20410\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:8629.98926#011validation-rmse:9321.28027\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:8564.39844#011validation-rmse:9261.72559\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:8500.85059#011validation-rmse:9205.40430\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:8440.91894#011validation-rmse:9151.95019\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:8405.91016#011validation-rmse:9124.52734\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:8349.95703#011validation-rmse:9065.26269\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:8320.47559#011validation-rmse:9030.28711\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:8252.69629#011validation-rmse:8972.10840\u001b[0m\n",
      "\u001b[34m[76]#011train-rmse:8217.82324#011validation-rmse:8936.64844\u001b[0m\n",
      "\u001b[34m[77]#011train-rmse:8171.72070#011validation-rmse:8892.28516\u001b[0m\n",
      "\u001b[34m[78]#011train-rmse:8154.70947#011validation-rmse:8876.80078\u001b[0m\n",
      "\u001b[34m[79]#011train-rmse:8125.49170#011validation-rmse:8851.68457\u001b[0m\n",
      "\u001b[34m[80]#011train-rmse:8092.35791#011validation-rmse:8822.12695\u001b[0m\n",
      "\u001b[34m[81]#011train-rmse:8061.50635#011validation-rmse:8794.87598\u001b[0m\n",
      "\u001b[34m[82]#011train-rmse:8016.51172#011validation-rmse:8755.45215\u001b[0m\n",
      "\u001b[34m[83]#011train-rmse:7951.27734#011validation-rmse:8700.00586\u001b[0m\n",
      "\u001b[34m[84]#011train-rmse:7886.47314#011validation-rmse:8633.42578\u001b[0m\n",
      "\u001b[34m[85]#011train-rmse:7846.66162#011validation-rmse:8598.17773\u001b[0m\n",
      "\u001b[34m[86]#011train-rmse:7782.87598#011validation-rmse:8540.70606\u001b[0m\n",
      "\u001b[34m[87]#011train-rmse:7716.45996#011validation-rmse:8488.54785\u001b[0m\n",
      "\u001b[34m[88]#011train-rmse:7650.40527#011validation-rmse:8432.69727\u001b[0m\n",
      "\u001b[34m[89]#011train-rmse:7616.06543#011validation-rmse:8405.33301\u001b[0m\n",
      "\u001b[34m[90]#011train-rmse:7541.54639#011validation-rmse:8336.90918\u001b[0m\n",
      "\u001b[34m[91]#011train-rmse:7521.75049#011validation-rmse:8320.03418\u001b[0m\n",
      "\u001b[34m[92]#011train-rmse:7483.82471#011validation-rmse:8277.13184\u001b[0m\n",
      "\u001b[34m[93]#011train-rmse:7452.59717#011validation-rmse:8250.14160\u001b[0m\n",
      "\u001b[34m[94]#011train-rmse:7397.97949#011validation-rmse:8206.05469\u001b[0m\n",
      "\u001b[34m[95]#011train-rmse:7370.80566#011validation-rmse:8180.01221\u001b[0m\n",
      "\u001b[34m[96]#011train-rmse:7331.64111#011validation-rmse:8148.97217\u001b[0m\n",
      "\u001b[34m[97]#011train-rmse:7262.86523#011validation-rmse:8086.73535\u001b[0m\n",
      "\u001b[34m[98]#011train-rmse:7238.92090#011validation-rmse:8065.17236\u001b[0m\n",
      "\u001b[34m[99]#011train-rmse:7183.73535#011validation-rmse:8015.27295\u001b[0m\n",
      "\n",
      "2022-11-25 17:07:38 Uploading - Uploading generated training model\n",
      "2022-11-25 17:07:38 Completed - Training job completed\n",
      "Training seconds: 108\n",
      "Billable seconds: 108\n"
     ]
    }
   ],
   "source": [
    "# Creating \"train\", \"validation\" channels to feed in the model\n",
    "# Source: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html\n",
    "\n",
    "train_input = sagemaker.session.s3_input(s3_data = s3_train_data, content_type='csv',s3_data_type = 'S3Prefix')\n",
    "valid_input = sagemaker.session.s3_input(s3_data = s3_validation_data, content_type='csv',s3_data_type = 'S3Prefix')\n",
    "data_channels = {'train': train_input,'validation': valid_input}\n",
    "Xgboost_regressor1.fit(data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #11: DEPLOY THE MODEL TO MAKE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "# Deploy the model to perform inference \n",
    "Xgboost_regressor = Xgboost_regressor1.deploy(initial_instance_count = 1, instance_type = 'ml.m5.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Content type over-rides the data that will be passed to the deployed model, since the deployed model expects data\n",
    "in text/csv format, we specify this as content -type.\n",
    "\n",
    "Serializer accepts a single argument, the input data, and returns a sequence of bytes in the specified content\n",
    "type\n",
    "\n",
    "Reference: https://sagemaker.readthedocs.io/en/stable/predictors.html\n",
    "'''\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "\n",
    "Xgboost_regressor.serializer = csv_serializer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105392, 138)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# making prediction\n",
    "predictions1 = Xgboost_regressor.predict(X_test[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "predictions2 = Xgboost_regressor.predict(X_test[10000:20000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "predictions3 = Xgboost_regressor.predict(X_test[20000:30000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "predictions4 = Xgboost_regressor.predict(X_test[30000:31618])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str(predictions4).split('n')[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom code to convert the values in bytes format to array\n",
    "def bytes_2_array(x):\n",
    "    \n",
    "    # makes entire prediction as string and splits based on ','\n",
    "    l = str(x).split('n')[:-1]\n",
    "    \n",
    "    # Since the first element contains unwanted characters like (b,',') we remove them\n",
    "    l[0] = l[0][2:]\n",
    "    #same-thing as above remove the unwanted last character (')\n",
    "    l[-1] = l[-1][:-1]\n",
    "    \n",
    "    # iterating through the list of strings and converting them into float type\n",
    "    for i in range(len(l)):\n",
    "        l[i] = float(l[i][:-1])\n",
    "        \n",
    "    # converting the list into array\n",
    "    l = np.array(l).astype('float32')\n",
    "    \n",
    "    # reshape one-dimensional array to two-dimensional array\n",
    "    return l.reshape(-1,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values_1 = bytes_2_array(predictions1)\n",
    "predicted_values_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values_2 = bytes_2_array(predictions2)\n",
    "predicted_values_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values_3 = bytes_2_array(predictions3)\n",
    "predicted_values_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1618, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values_4 = bytes_2_array(predictions4)\n",
    "predicted_values_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = np.concatenate((predicted_values_1, predicted_values_2, predicted_values_3, predicted_values_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31618, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [105392, 31618]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9a79b0b5da57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mRMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.3f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mMAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 252\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [105392, 31618]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, predicted_values)),'.3f'))\n",
    "MSE = mean_squared_error(y_test, predicted_values)\n",
    "MAE = mean_absolute_error(y_test, predicted_values)\n",
    "r2 = r2_score(y_test, predicted_values)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Xgboost_regressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d3f3e99ae008>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Delete the end-point\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mXgboost_regressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelete_endpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Xgboost_regressor' is not defined"
     ]
    }
   ],
   "source": [
    "# Delete the end-point\n",
    "Xgboost_regressor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #12: PERFORM HYPERPARAMETERS OPTIMIZATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See Slides for detailed steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #13: TRAIN THE MODEL WITH BEST PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have pass in the container, the type of instance that we would like to use for training \n",
    "# output path and sagemaker session into the Estimator. \n",
    "# We can also specify how many instances we would like to use for training\n",
    "\n",
    "Xgboost_regressor = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count=1, \n",
    "                                       train_instance_type='ml.m5.2xlarge',\n",
    "                                       output_path=output_location,\n",
    "                                       sagemaker_session=sagemaker_session)\n",
    "\n",
    "# We can tune the hyper-parameters to improve the performance of the model\n",
    "Xgboost_regressor.set_hyperparameters(max_depth=25,\n",
    "                           objective='reg:linear',\n",
    "                           colsample_bytree = 0.3913546819101119,\n",
    "                           alpha = 1.0994354985124635,\n",
    "                           eta = 0.23848185159806115,\n",
    "                           num_round = 237\n",
    "                           )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = sagemaker.session.s3_input(s3_data = s3_train_data, content_type='csv',s3_data_type = 'S3Prefix')\n",
    "valid_input = sagemaker.session.s3_input(s3_data = s3_validation_data, content_type='csv',s3_data_type = 'S3Prefix')\n",
    "data_channels = {'train': train_input,'validation': valid_input}\n",
    "Xgboost_regressor.fit(data_channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploying the model to perform inference\n",
    "\n",
    "Xgboost_regressor = Xgboost_regressor.deploy(initial_instance_count = 1,\n",
    "                                             instance_type = 'ml.m5.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "Xgboost_regressor.serializer = csv_serializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Try to make inference with the entire testing dataset (Crashes!)\n",
    "#predictions = Xgboost_regressor.predict(X_test)\n",
    "#predicted_values = bytes_2_array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions1 = Xgboost_regressor.predict(X_test[0:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values_1 = bytes_2_array(predictions1)\n",
    "predicted_values_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = Xgboost_regressor.predict(X_test[10000:20000])\n",
    "predicted_values_2 = bytes_2_array(predictions2)\n",
    "predicted_values_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions3 = Xgboost_regressor.predict(X_test[20000:30000])\n",
    "predicted_values_3 = bytes_2_array(predictions3)\n",
    "predicted_values_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions4 = Xgboost_regressor.predict(X_test[30000:31618])\n",
    "predicted_values_4 = bytes_2_array(predictions4)\n",
    "predicted_values_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = np.concatenate((predicted_values_1, predicted_values_2, predicted_values_3, predicted_values_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, predicted_values)),'.3f'))\n",
    "MSE = mean_squared_error(y_test, predicted_values)\n",
    "MAE = mean_absolute_error(y_test, predicted_values)\n",
    "r2 = r2_score(y_test, predicted_values)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the end-point\n",
    "Xgboost_regressor.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Retail Sales Forecast.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
