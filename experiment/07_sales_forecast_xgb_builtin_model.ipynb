{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8NQ05Yg6Dfcq"
   },
   "source": [
    "# TASK #1: UNDERSTAND THE PROBLEM STATEMENT/GOAL\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This dataset contains weekly sales from 99 departments belonging to 45 different stores. \n",
    "- Our aim is to forecast weekly sales from a particular department.\n",
    "- The objective of this case study is to forecast weekly retail store sales based on historical data.\n",
    "- The data contains holidays and promotional markdowns offered by various stores and several departments throughout the year.\n",
    "- Markdowns are crucial to promote sales especially before key events such as Super Bowl, Christmas and Thanksgiving. \n",
    "- Developing accurate model will enable make informed decisions and make recommendations to improve business processes in the future. \n",
    "- The data consists of three sheets: \n",
    "    - Stores\n",
    "    - Features\n",
    "    - Sales\n",
    "- Data Source : https://www.kaggle.com/manjeetsingh/retaildataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TprtqAhLn9w8"
   },
   "source": [
    "# TASK #2: IMPORT DATASET AND LIBRARIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PVrKXCk4njhr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import zipfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>Dept</th>\n",
       "      <th>Date</th>\n",
       "      <th>Weekly_Sales</th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>month</th>\n",
       "      <th>Type</th>\n",
       "      <th>Size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>24924.50</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>50605.27</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>13740.12</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>39954.04</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2010-05-02</td>\n",
       "      <td>32229.38</td>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>5</td>\n",
       "      <td>A</td>\n",
       "      <td>151315</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  Dept        Date  Weekly_Sales  IsHoliday  Temperature  Fuel_Price  \\\n",
       "0      1     1  2010-05-02      24924.50          0        42.31       2.572   \n",
       "1      1     2  2010-05-02      50605.27          0        42.31       2.572   \n",
       "2      1     3  2010-05-02      13740.12          0        42.31       2.572   \n",
       "3      1     4  2010-05-02      39954.04          0        42.31       2.572   \n",
       "4      1     5  2010-05-02      32229.38          0        42.31       2.572   \n",
       "\n",
       "   MarkDown1  MarkDown2  MarkDown3  MarkDown4  MarkDown5         CPI  \\\n",
       "0        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "1        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "2        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "3        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "4        0.0        0.0        0.0        0.0        0.0  211.096358   \n",
       "\n",
       "   Unemployment  month Type    Size  \n",
       "0         8.106      5    A  151315  \n",
       "1         8.106      5    A  151315  \n",
       "2         8.106      5    A  151315  \n",
       "3         8.106      5    A  151315  \n",
       "4         8.106      5    A  151315  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/data_processed.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the date\n",
    "y = df['Weekly_Sales'] # target\n",
    "X = df.drop(columns = ['Weekly_Sales', 'Date']) # features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.get_dummies(X, columns = ['Type', 'Store', 'Dept'], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421570, 138)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421570,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IsHoliday</th>\n",
       "      <th>Temperature</th>\n",
       "      <th>Fuel_Price</th>\n",
       "      <th>MarkDown1</th>\n",
       "      <th>MarkDown2</th>\n",
       "      <th>MarkDown3</th>\n",
       "      <th>MarkDown4</th>\n",
       "      <th>MarkDown5</th>\n",
       "      <th>CPI</th>\n",
       "      <th>Unemployment</th>\n",
       "      <th>...</th>\n",
       "      <th>Dept_90</th>\n",
       "      <th>Dept_91</th>\n",
       "      <th>Dept_92</th>\n",
       "      <th>Dept_93</th>\n",
       "      <th>Dept_94</th>\n",
       "      <th>Dept_95</th>\n",
       "      <th>Dept_96</th>\n",
       "      <th>Dept_97</th>\n",
       "      <th>Dept_98</th>\n",
       "      <th>Dept_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>42.31</td>\n",
       "      <td>2.572</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>211.096358</td>\n",
       "      <td>8.106</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IsHoliday  Temperature  Fuel_Price  MarkDown1  MarkDown2  MarkDown3  \\\n",
       "0          0        42.31       2.572        0.0        0.0        0.0   \n",
       "1          0        42.31       2.572        0.0        0.0        0.0   \n",
       "2          0        42.31       2.572        0.0        0.0        0.0   \n",
       "3          0        42.31       2.572        0.0        0.0        0.0   \n",
       "4          0        42.31       2.572        0.0        0.0        0.0   \n",
       "\n",
       "   MarkDown4  MarkDown5         CPI  Unemployment  ...  Dept_90  Dept_91  \\\n",
       "0        0.0        0.0  211.096358         8.106  ...        0        0   \n",
       "1        0.0        0.0  211.096358         8.106  ...        0        0   \n",
       "2        0.0        0.0  211.096358         8.106  ...        0        0   \n",
       "3        0.0        0.0  211.096358         8.106  ...        0        0   \n",
       "4        0.0        0.0  211.096358         8.106  ...        0        0   \n",
       "\n",
       "   Dept_92  Dept_93  Dept_94  Dept_95  Dept_96  Dept_97  Dept_98  Dept_99  \n",
       "0        0        0        0        0        0        0        0        0  \n",
       "1        0        0        0        0        0        0        0        0  \n",
       "2        0        0        0        0        0        0        0        0  \n",
       "3        0        0        0        0        0        0        0        0  \n",
       "4        0        0        0        0        0        0        0        0  \n",
       "\n",
       "[5 rows x 138 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save columnames for later purposes\n",
    "featurenames = list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X).astype('float32')\n",
    "y = np.array(y).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(421570, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshaping the array from (421570,) to (421570, 1)\n",
    "y = y.reshape(-1,1)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spliting the data into train, validation and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.75)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(105392, 138)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158089, 138)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158089, 138)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAIN XGBOOST USING SAGEMAKER Builtin Algorithm with Optimized Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# Convert the array into dataframe in a way that target variable is set as the first column and followed by feature columns\n",
    "# This is because sagemaker built-in algorithm expects the data in this format.\n",
    "\n",
    "train_data = pd.DataFrame({'Target': y_train[:,0]})\n",
    "for i in range(X_train.shape[1]):\n",
    "    train_data[i] = X_train[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12629.080078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.400002</td>\n",
       "      <td>3.016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>211.486465</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2252.310059</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66.190002</td>\n",
       "      <td>2.732</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>190.294830</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5703.939941</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72.620003</td>\n",
       "      <td>2.780</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>182.442413</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3924.139893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47.660000</td>\n",
       "      <td>3.162</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>126.669266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10619.610352</td>\n",
       "      <td>0.0</td>\n",
       "      <td>79.470001</td>\n",
       "      <td>3.452</td>\n",
       "      <td>6401.419922</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.01</td>\n",
       "      <td>744.859985</td>\n",
       "      <td>7363.359863</td>\n",
       "      <td>221.387741</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target    0          1      2            3    4     5           6  \\\n",
       "0  12629.080078  0.0  41.400002  3.016     0.000000  0.0  0.00    0.000000   \n",
       "1   2252.310059  0.0  66.190002  2.732     0.000000  0.0  0.00    0.000000   \n",
       "2   5703.939941  0.0  72.620003  2.780     0.000000  0.0  0.00    0.000000   \n",
       "3   3924.139893  1.0  47.660000  3.162     0.000000  0.0  0.00    0.000000   \n",
       "4  10619.610352  0.0  79.470001  3.452  6401.419922  0.0  1.01  744.859985   \n",
       "\n",
       "             7           8  ...  128  129  130  131  132  133  134  135  136  \\\n",
       "0     0.000000  211.486465  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1     0.000000  190.294830  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2     0.000000  182.442413  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3     0.000000  126.669266  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4  7363.359863  221.387741  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   137  \n",
       "0  0.0  \n",
       "1  0.0  \n",
       "2  0.0  \n",
       "3  0.0  \n",
       "4  0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "val_data = pd.DataFrame({'Target':y_val[:,0]})\n",
    "for i in range(X_val.shape[1]):\n",
    "    val_data[i] = X_val[:,i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>128</th>\n",
       "      <th>129</th>\n",
       "      <th>130</th>\n",
       "      <th>131</th>\n",
       "      <th>132</th>\n",
       "      <th>133</th>\n",
       "      <th>134</th>\n",
       "      <th>135</th>\n",
       "      <th>136</th>\n",
       "      <th>137</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5201.270020</td>\n",
       "      <td>0.0</td>\n",
       "      <td>86.910004</td>\n",
       "      <td>3.417</td>\n",
       "      <td>7365.259766</td>\n",
       "      <td>14.48</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>3640.699951</td>\n",
       "      <td>2517.310059</td>\n",
       "      <td>222.538513</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15287.480469</td>\n",
       "      <td>0.0</td>\n",
       "      <td>67.790001</td>\n",
       "      <td>3.979</td>\n",
       "      <td>10665.280273</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1095.849976</td>\n",
       "      <td>1053.959961</td>\n",
       "      <td>2647.449951</td>\n",
       "      <td>138.110199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6520.379883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.139999</td>\n",
       "      <td>2.983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>211.117676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.299999</td>\n",
       "      <td>2.976</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>211.956024</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13316.459961</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69.160004</td>\n",
       "      <td>3.784</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.196991</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Target    0          1      2             3      4            5  \\\n",
       "0   5201.270020  0.0  86.910004  3.417   7365.259766  14.48     0.700000   \n",
       "1  15287.480469  0.0  67.790001  3.979  10665.280273   0.00  1095.849976   \n",
       "2   6520.379883  0.0  34.139999  2.983      0.000000   0.00     0.000000   \n",
       "3     75.000000  0.0  48.299999  2.976      0.000000   0.00     0.000000   \n",
       "4  13316.459961  0.0  69.160004  3.784      0.000000   0.00     0.000000   \n",
       "\n",
       "             6            7           8  ...  128  129  130  131  132  133  \\\n",
       "0  3640.699951  2517.310059  222.538513  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "1  1053.959961  2647.449951  138.110199  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "2     0.000000     0.000000  211.117676  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "3     0.000000     0.000000  211.956024  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "4     0.000000     0.000000  140.196991  ...  0.0  0.0  0.0  0.0  0.0  0.0   \n",
       "\n",
       "   134  135  136  137  \n",
       "0  0.0  0.0  0.0  0.0  \n",
       "1  0.0  0.0  0.0  0.0  \n",
       "2  0.0  0.0  0.0  0.0  \n",
       "3  0.0  0.0  0.0  0.0  \n",
       "4  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 139 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158089, 139)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train_data and validation_data as csv files.\n",
    "train_data.to_csv('../data/train.csv', header = False, index = False)\n",
    "val_data.to_csv('../data/validation.csv', header = False, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boto3 is the Amazon Web Services (AWS) Software Development Kit (SDK) for Python\n",
    "# Boto3 allows Python developer to write software that makes use of services like Amazon S3 and Amazon EC2\n",
    "\n",
    "import sagemaker\n",
    "import boto3\n",
    "from sagemaker import Session\n",
    "\n",
    "# Let's create a Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "#bucket = Session().default_bucket() \n",
    "bucket = 'salesprediction-ml-sagemaker'\n",
    "prefix = 'XGBoost-Regressor'\n",
    "key = 'XGBoost-Regressor'\n",
    "#Roles give learning and hosting access to the data\n",
    "#This is specified while opening the sagemakers instance in \"Create an IAM role\"\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arn:aws:iam::103721820087:role/service-role/AmazonSageMaker-ExecutionRole-20190909T202771\n"
     ]
    }
   ],
   "source": [
    "print(role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded training data location: s3://salesprediction-ml-sagemaker/XGBoost-Regressor/train/XGBoost-Regressor\n"
     ]
    }
   ],
   "source": [
    "# read the data from csv file and then upload the data to s3 bucket\n",
    "import os\n",
    "with open('../data/train.csv','rb') as f:\n",
    "    # The following code uploads the data into S3 bucket to be accessed later for training\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', key)).upload_fileobj(f)\n",
    "\n",
    "# Let's print out the training data location in s3\n",
    "s3_train_data = 's3://{}/{}/train/{}'.format(bucket, prefix, key)\n",
    "print('uploaded training data location: {}'.format(s3_train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "uploaded validation data location: s3://salesprediction-ml-sagemaker/XGBoost-Regressor/validation/XGBoost-Regressor\n"
     ]
    }
   ],
   "source": [
    "# read the data from csv file and then upload the data to s3 bucket\n",
    "\n",
    "with open('../data/validation.csv','rb') as f:\n",
    "    # The following code uploads the data into S3 bucket to be accessed later for training\n",
    "\n",
    "    boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation', key)).upload_fileobj(f)\n",
    "# Let's print out the validation data location in s3\n",
    "s3_validation_data = 's3://{}/{}/validation/{}'.format(bucket, prefix, key)\n",
    "print('uploaded validation data location: {}'.format(s3_validation_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training artifacts will be uploaded to: s3://salesprediction-ml-sagemaker/XGBoost-Regressor/output\n"
     ]
    }
   ],
   "source": [
    "# creates output placeholder in S3 bucket to store the output\n",
    "output_location = 's3://{}/{}/output'.format(bucket, prefix)\n",
    "print('training artifacts will be uploaded to: {}'.format(output_location))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The method get_image_uri has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# This code is used to get the training container of sagemaker built-in algorithms\n",
    "# all we have to do is to specify the name of the algorithm, that we want to use\n",
    "\n",
    "# Let's obtain a reference to the XGBoost container image\n",
    "# Note that all regression models are named estimators\n",
    "# You don't have to specify (hardcode) the region, get_image_uri will get the current region name using boto3.Session\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "container = get_image_uri(boto3.Session().region_name, \n",
    "                          'xgboost',\n",
    "                          #'0.90-2', \n",
    "                          '1.5-1') # Latest version of XGboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remember, the best hyperparameters found were:\n",
    "# 'clf__colsample_bytree': 0.1, 'clf__max_depth': 4, 'clf__n_estimators': 25}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# Specify the type of instance that we would like to use for training \n",
    "# output path and sagemaker session into the Estimator. \n",
    "# We can also specify how many instances we would like to use for training\n",
    "\n",
    "# Recall that XGBoost works by combining an ensemble of weak models to generate accurate/robust results. \n",
    "# The weak models are randomized to avoid overfitting\n",
    "\n",
    "# num_round: The number of rounds to run the training.\n",
    "\n",
    "\n",
    "# Alpha: L1 regularization term on weights. Increasing this value makes models more conservative.\n",
    "\n",
    "# colsample_by_tree: fraction of features that will be used to train each tree.\n",
    "\n",
    "# eta: Step size shrinkage used in updates to prevent overfitting. \n",
    "# After each boosting step, eta parameter shrinks the feature weights to make the boosting process more conservative.\n",
    "\n",
    "\n",
    "Xgboost_regressor = sagemaker.estimator.Estimator(container,\n",
    "                                       role, \n",
    "                                       train_instance_count = 1, \n",
    "                                       train_instance_type = 'ml.m5.2xlarge',\n",
    "                                       output_path = output_location,\n",
    "                                       sagemaker_session = sagemaker_session)\n",
    "\n",
    "#We can tune the hyper-parameters to improve the performance of the model\n",
    "\n",
    "Xgboost_regressor.set_hyperparameters(max_depth = 4,\n",
    "                           objective = 'reg:linear',\n",
    "                           colsample_bytree = 0.1,\n",
    "                           # n_estimators = 25, --> not a valid hyperparameter for the built in version!\n",
    "                           num_round = 100\n",
    "                           )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The class sagemaker.session.s3_input has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-11-29 09:22:40 Starting - Starting the training job...\n",
      "2022-11-29 09:23:04 Starting - Preparing the instances for trainingProfilerReport-1669713760: InProgress\n",
      ".........\n",
      "2022-11-29 09:24:24 Downloading - Downloading input data...\n",
      "2022-11-29 09:25:05 Training - Downloading the training image..\u001b[34m[2022-11-29 09:25:17.033 ip-10-0-142-184.ec2.internal:7 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:17:INFO] Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:17:INFO] Failed to parse hyperparameter objective value reg:linear to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:17:INFO] No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:17:INFO] Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:17:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:17:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:17:INFO] files path: /opt/ml/input/data/train\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:17:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:17:INFO] files path: /opt/ml/input/data/validation\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:17:INFO] Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:18:INFO] Single node training.\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:18:INFO] Train matrix has 105392 rows and 138 columns\u001b[0m\n",
      "\u001b[34m[2022-11-29:09:25:18:INFO] Validation matrix has 158089 rows\u001b[0m\n",
      "\u001b[34m[2022-11-29 09:25:18.125 ip-10-0-142-184.ec2.internal:7 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.\u001b[0m\n",
      "\u001b[34m[09:25:18] WARNING: ../src/objective/regression_obj.cu:188: reg:linear is now deprecated in favor of reg:squarederror.\u001b[0m\n",
      "\u001b[34m[0]#011train-rmse:24601.01367#011validation-rmse:24666.92578\u001b[0m\n",
      "\u001b[34m[1]#011train-rmse:22853.05859#011validation-rmse:22920.65625\u001b[0m\n",
      "\u001b[34m[2]#011train-rmse:22078.08789#011validation-rmse:22151.97461\u001b[0m\n",
      "\u001b[34m[3]#011train-rmse:21604.28516#011validation-rmse:21682.76758\u001b[0m\n",
      "\u001b[34m[4]#011train-rmse:21148.63281#011validation-rmse:21226.81445\u001b[0m\n",
      "\u001b[34m[5]#011train-rmse:20738.80273#011validation-rmse:20812.13477\u001b[0m\n",
      "\u001b[34m[6]#011train-rmse:20198.93945#011validation-rmse:20281.28320\u001b[0m\n",
      "\u001b[34m[7]#011train-rmse:19929.05664#011validation-rmse:20014.53125\u001b[0m\n",
      "\u001b[34m[8]#011train-rmse:19861.69531#011validation-rmse:19948.40820\u001b[0m\n",
      "\u001b[34m[9]#011train-rmse:19423.85742#011validation-rmse:19523.87695\u001b[0m\n",
      "\u001b[34m[10]#011train-rmse:19210.26172#011validation-rmse:19312.09375\u001b[0m\n",
      "\u001b[34m[11]#011train-rmse:19124.38867#011validation-rmse:19225.38281\u001b[0m\n",
      "\u001b[34m[12]#011train-rmse:18901.31641#011validation-rmse:19003.80469\u001b[0m\n",
      "\u001b[34m[13]#011train-rmse:18604.58789#011validation-rmse:18720.67383\u001b[0m\n",
      "\u001b[34m[14]#011train-rmse:18484.16797#011validation-rmse:18604.24414\u001b[0m\n",
      "\u001b[34m[15]#011train-rmse:18198.73438#011validation-rmse:18333.12109\u001b[0m\n",
      "\u001b[34m[16]#011train-rmse:17352.11719#011validation-rmse:17533.26562\u001b[0m\n",
      "\u001b[34m[17]#011train-rmse:17211.46484#011validation-rmse:17404.35352\u001b[0m\n",
      "\u001b[34m[18]#011train-rmse:16677.40625#011validation-rmse:16896.74414\u001b[0m\n",
      "\u001b[34m[19]#011train-rmse:16383.72461#011validation-rmse:16612.44727\u001b[0m\n",
      "\u001b[34m[20]#011train-rmse:16226.02734#011validation-rmse:16467.71094\u001b[0m\n",
      "\u001b[34m[21]#011train-rmse:15730.32715#011validation-rmse:15991.45410\u001b[0m\n",
      "\u001b[34m[22]#011train-rmse:15659.91894#011validation-rmse:15917.24023\u001b[0m\n",
      "\u001b[34m[23]#011train-rmse:15527.52148#011validation-rmse:15790.51953\u001b[0m\n",
      "\u001b[34m[24]#011train-rmse:15428.59961#011validation-rmse:15691.60352\u001b[0m\n",
      "\u001b[34m[25]#011train-rmse:15247.74219#011validation-rmse:15523.82812\u001b[0m\n",
      "\u001b[34m[26]#011train-rmse:15171.10742#011validation-rmse:15447.18262\u001b[0m\n",
      "\u001b[34m[27]#011train-rmse:14563.56348#011validation-rmse:14859.38867\u001b[0m\n",
      "\u001b[34m[28]#011train-rmse:14407.21387#011validation-rmse:14717.83496\u001b[0m\n",
      "\u001b[34m[29]#011train-rmse:14248.34570#011validation-rmse:14586.10644\u001b[0m\n",
      "\u001b[34m[30]#011train-rmse:13909.53027#011validation-rmse:14272.54590\u001b[0m\n",
      "\u001b[34m[31]#011train-rmse:13818.30469#011validation-rmse:14192.04004\u001b[0m\n",
      "\u001b[34m[32]#011train-rmse:13603.47852#011validation-rmse:13972.90625\u001b[0m\n",
      "\u001b[34m[33]#011train-rmse:13570.20898#011validation-rmse:13942.72754\u001b[0m\n",
      "\u001b[34m[34]#011train-rmse:13524.49805#011validation-rmse:13899.87598\u001b[0m\n",
      "\u001b[34m[35]#011train-rmse:13446.11328#011validation-rmse:13824.56934\u001b[0m\n",
      "\u001b[34m[36]#011train-rmse:13402.07324#011validation-rmse:13783.17090\u001b[0m\n",
      "\u001b[34m[37]#011train-rmse:13296.91797#011validation-rmse:13684.92871\u001b[0m\n",
      "\u001b[34m[38]#011train-rmse:13127.18555#011validation-rmse:13526.63379\u001b[0m\n",
      "\u001b[34m[39]#011train-rmse:13095.61719#011validation-rmse:13500.70801\u001b[0m\n",
      "\u001b[34m[40]#011train-rmse:13028.21387#011validation-rmse:13433.21094\u001b[0m\n",
      "\u001b[34m[41]#011train-rmse:12988.05859#011validation-rmse:13395.06543\u001b[0m\n",
      "\u001b[34m[42]#011train-rmse:12956.91797#011validation-rmse:13364.92285\u001b[0m\n",
      "\u001b[34m[43]#011train-rmse:12784.15918#011validation-rmse:13200.57422\u001b[0m\n",
      "\u001b[34m[44]#011train-rmse:12763.53027#011validation-rmse:13182.48828\u001b[0m\n",
      "\u001b[34m[45]#011train-rmse:12744.87402#011validation-rmse:13164.62598\u001b[0m\n",
      "\u001b[34m[46]#011train-rmse:12714.14746#011validation-rmse:13136.74414\u001b[0m\n",
      "\u001b[34m[47]#011train-rmse:12656.23731#011validation-rmse:13085.10938\u001b[0m\n",
      "\u001b[34m[48]#011train-rmse:12613.99512#011validation-rmse:13049.10449\u001b[0m\n",
      "\u001b[34m[49]#011train-rmse:12575.69336#011validation-rmse:13012.84180\u001b[0m\n",
      "\u001b[34m[50]#011train-rmse:12422.20996#011validation-rmse:12864.71680\u001b[0m\n",
      "\u001b[34m[51]#011train-rmse:12346.30566#011validation-rmse:12789.55078\u001b[0m\n",
      "\u001b[34m[52]#011train-rmse:12277.91016#011validation-rmse:12737.00391\u001b[0m\n",
      "\u001b[34m[53]#011train-rmse:12256.05566#011validation-rmse:12714.53613\u001b[0m\n",
      "\u001b[34m[54]#011train-rmse:12227.94434#011validation-rmse:12685.13965\u001b[0m\n",
      "\u001b[34m[55]#011train-rmse:12195.05176#011validation-rmse:12650.37598\u001b[0m\n",
      "\u001b[34m[56]#011train-rmse:12169.46875#011validation-rmse:12628.41211\u001b[0m\n",
      "\u001b[34m[57]#011train-rmse:12134.18945#011validation-rmse:12597.24707\u001b[0m\n",
      "\u001b[34m[58]#011train-rmse:12113.01562#011validation-rmse:12577.72070\u001b[0m\n",
      "\u001b[34m[59]#011train-rmse:11943.47949#011validation-rmse:12435.87793\u001b[0m\n",
      "\u001b[34m[60]#011train-rmse:11753.79199#011validation-rmse:12249.95898\u001b[0m\n",
      "\u001b[34m[61]#011train-rmse:11736.77734#011validation-rmse:12233.76074\u001b[0m\n",
      "\u001b[34m[62]#011train-rmse:11656.86426#011validation-rmse:12159.99121\u001b[0m\n",
      "\u001b[34m[63]#011train-rmse:11619.58106#011validation-rmse:12125.48047\u001b[0m\n",
      "\u001b[34m[64]#011train-rmse:11598.31445#011validation-rmse:12105.41113\u001b[0m\n",
      "\u001b[34m[65]#011train-rmse:11586.41309#011validation-rmse:12093.55176\u001b[0m\n",
      "\u001b[34m[66]#011train-rmse:11563.69629#011validation-rmse:12073.95019\u001b[0m\n",
      "\u001b[34m[67]#011train-rmse:11528.18457#011validation-rmse:12041.45703\u001b[0m\n",
      "\u001b[34m[68]#011train-rmse:11498.75977#011validation-rmse:12014.82910\u001b[0m\n",
      "\u001b[34m[69]#011train-rmse:11481.02832#011validation-rmse:11998.46094\u001b[0m\n",
      "\u001b[34m[70]#011train-rmse:11437.49414#011validation-rmse:11959.87402\u001b[0m\n",
      "\u001b[34m[71]#011train-rmse:11418.91602#011validation-rmse:11943.02930\u001b[0m\n",
      "\u001b[34m[72]#011train-rmse:11401.59082#011validation-rmse:11927.26660\u001b[0m\n",
      "\u001b[34m[73]#011train-rmse:11379.60352#011validation-rmse:11906.37012\u001b[0m\n",
      "\u001b[34m[74]#011train-rmse:11251.37695#011validation-rmse:11794.14062\u001b[0m\n",
      "\u001b[34m[75]#011train-rmse:11132.32129#011validation-rmse:11675.41602\u001b[0m\n",
      "\u001b[34m[76]#011train-rmse:11116.19434#011validation-rmse:11658.98144\u001b[0m\n",
      "\u001b[34m[77]#011train-rmse:11106.76758#011validation-rmse:11650.48926\u001b[0m\n",
      "\u001b[34m[78]#011train-rmse:11087.33789#011validation-rmse:11632.99219\u001b[0m\n",
      "\u001b[34m[79]#011train-rmse:11077.79492#011validation-rmse:11622.00781\u001b[0m\n",
      "\u001b[34m[80]#011train-rmse:11061.20410#011validation-rmse:11605.26367\u001b[0m\n",
      "\u001b[34m[81]#011train-rmse:11045.34180#011validation-rmse:11589.42676\u001b[0m\n",
      "\u001b[34m[82]#011train-rmse:11019.01172#011validation-rmse:11560.90625\u001b[0m\n",
      "\u001b[34m[83]#011train-rmse:11002.98047#011validation-rmse:11546.83887\u001b[0m\n",
      "\u001b[34m[84]#011train-rmse:10975.23926#011validation-rmse:11517.62305\u001b[0m\n",
      "\u001b[34m[85]#011train-rmse:10968.12988#011validation-rmse:11509.83691\u001b[0m\n",
      "\u001b[34m[86]#011train-rmse:10887.90820#011validation-rmse:11444.44531\u001b[0m\n",
      "\u001b[34m[87]#011train-rmse:10873.37500#011validation-rmse:11432.35547\u001b[0m\n",
      "\u001b[34m[88]#011train-rmse:10842.89258#011validation-rmse:11410.07910\u001b[0m\n",
      "\u001b[34m[89]#011train-rmse:10832.66504#011validation-rmse:11398.44336\u001b[0m\n",
      "\u001b[34m[90]#011train-rmse:10802.36133#011validation-rmse:11366.32910\u001b[0m\n",
      "\u001b[34m[91]#011train-rmse:10766.04297#011validation-rmse:11338.99023\u001b[0m\n",
      "\u001b[34m[92]#011train-rmse:10674.67383#011validation-rmse:11269.16894\u001b[0m\n",
      "\u001b[34m[93]#011train-rmse:10665.55371#011validation-rmse:11259.17090\u001b[0m\n",
      "\u001b[34m[94]#011train-rmse:10647.81445#011validation-rmse:11243.90137\u001b[0m\n",
      "\u001b[34m[95]#011train-rmse:10617.69531#011validation-rmse:11217.21973\u001b[0m\n",
      "\u001b[34m[96]#011train-rmse:10599.06055#011validation-rmse:11199.67188\u001b[0m\n",
      "\u001b[34m[97]#011train-rmse:10544.32031#011validation-rmse:11147.75879\u001b[0m\n",
      "\u001b[34m[98]#011train-rmse:10536.79004#011validation-rmse:11140.31738\u001b[0m\n",
      "\u001b[34m[99]#011train-rmse:10524.50977#011validation-rmse:11130.37402\u001b[0m\n",
      "\n",
      "2022-11-29 09:25:40 Uploading - Uploading generated training model\n",
      "2022-11-29 09:25:40 Completed - Training job completed\n",
      "Training seconds: 87\n",
      "Billable seconds: 87\n"
     ]
    }
   ],
   "source": [
    "# Creating \"train\", \"validation\" channels to feed in the model\n",
    "# Source: https://docs.aws.amazon.com/sagemaker/latest/dg/sagemaker-algo-docker-registry-paths.html\n",
    "\n",
    "train_input = sagemaker.session.s3_input(s3_data = s3_train_data, content_type='csv',s3_data_type = 'S3Prefix')\n",
    "valid_input = sagemaker.session.s3_input(s3_data = s3_validation_data, content_type='csv',s3_data_type = 'S3Prefix')\n",
    "data_channels = {'train': train_input,'validation': valid_input}\n",
    "Xgboost_regressor.fit(data_channels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TASK #11: DEPLOY THE MODEL TO MAKE PREDICTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!"
     ]
    }
   ],
   "source": [
    "# Deploy the model to perform inference \n",
    "predictor = Xgboost_regressor.deploy(initial_instance_count = 1, instance_type = 'ml.m5.2xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Content type over-rides the data that will be passed to the deployed model, since the deployed model expects data\n",
    "in text/csv format, we specify this as content -type.\n",
    "\n",
    "Serializer accepts a single argument, the input data, and returns a sequence of bytes in the specified content\n",
    "type\n",
    "\n",
    "Reference: https://sagemaker.readthedocs.io/en/stable/predictors.html\n",
    "'''\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(158089, 138)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The csv_serializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "The json_deserializer has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "# making prediction\n",
    "predictions1 = predictor.predict(X_test[0:10000])\n",
    "predictions2 = predictor.predict(X_test[10000:20000])\n",
    "predictions3 = predictor.predict(X_test[20000:30000])\n",
    "predictions4 = predictor.predict(X_test[30000:40000])\n",
    "predictions5 = predictor.predict(X_test[40000:50000])\n",
    "predictions6 = predictor.predict(X_test[50000:60000])\n",
    "predictions7 = predictor.predict(X_test[60000:70000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case the json_deserializer has been used, then use this function for decoding the predictions into an array\n",
    "def json_predictions_2_array(json_predictions:dict)->np.array:\n",
    "    return np.array([pred['score'] for pred in json_predictions['predictions']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values_1 = json_predictions_2_array(predictions1)\n",
    "predicted_values_2 = json_predictions_2_array(predictions2)\n",
    "predicted_values_3 = json_predictions_2_array(predictions3)\n",
    "predicted_values_4 = json_predictions_2_array(predictions4)\n",
    "predicted_values_5 = json_predictions_2_array(predictions5)\n",
    "predicted_values_6 = json_predictions_2_array(predictions6)\n",
    "predicted_values_7 = json_predictions_2_array(predictions7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(70000,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values = np.concatenate((predicted_values_1, \n",
    "                                   predicted_values_2,\n",
    "                                  predicted_values_3,\n",
    "                                  predicted_values_4,\n",
    "                                  predicted_values_5,\n",
    "                                  predicted_values_6,\n",
    "                                  predicted_values_7))\n",
    "predicted_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 11057.331 \n",
      "MSE = 122264559.1669434 \n",
      "MAE = 6523.909642425309 \n",
      "R2 = 0.7605392853770345 \n",
      "Adjusted R2 = 0.760066266401956\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "k = X_test[:70000].shape[1]\n",
    "n = len(X_test[:70000])\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test[:70000], predicted_values)),'.3f'))\n",
    "MSE = mean_squared_error(y_test[:70000], predicted_values)\n",
    "MAE = mean_absolute_error(y_test[:70000], predicted_values)\n",
    "r2 = r2_score(y_test[:70000], predicted_values)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case the json_deserialzer has not been used, then the byte array can be decoded using this function\n",
    "# custom code to convert the values in bytes format to array\n",
    "def bytes_2_array(x):\n",
    "    \n",
    "    # makes entire prediction as string and splits based on ','\n",
    "    l = str(x).split('n')[:-1]\n",
    "    \n",
    "    # Since the first element contains unwanted characters like (b,',') we remove them\n",
    "    l[0] = l[0][2:]\n",
    "    #same-thing as above remove the unwanted last character (')\n",
    "    l[-1] = l[-1][:-1]\n",
    "    \n",
    "    # iterating through the list of strings and converting them into float type\n",
    "    for i in range(len(l)):\n",
    "        l[i] = float(l[i][:-1])\n",
    "        \n",
    "    # converting the list into array\n",
    "    l = np.array(l).astype('float32')\n",
    "    \n",
    "    # reshape one-dimensional array to two-dimensional array\n",
    "    return l.reshape(-1,1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values_1 = bytes_2_array(predictions1)\n",
    "predicted_values_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values_2 = bytes_2_array(predictions2)\n",
    "predicted_values_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values_3 = bytes_2_array(predictions3)\n",
    "predicted_values_3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1618, 1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values_4 = bytes_2_array(predictions4)\n",
    "predicted_values_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_values = np.concatenate((predicted_values_1, predicted_values_2, predicted_values_3, predicted_values_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31618, 1)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [105392, 31618]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-9a79b0b5da57>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mRMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'.3f'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mMSE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mMAE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_values\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \"\"\"\n\u001b[1;32m    251\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[0;32m--> 252\u001b[0;31m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[0;34m(y_true, y_pred, multioutput, dtype)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m     \"\"\"\n\u001b[0;32m---> 84\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m     \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_2d\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 212\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [105392, 31618]"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from math import sqrt\n",
    "k = X_test.shape[1]\n",
    "n = len(X_test)\n",
    "RMSE = float(format(np.sqrt(mean_squared_error(y_test, predicted_values)),'.3f'))\n",
    "MSE = mean_squared_error(y_test, predicted_values)\n",
    "MAE = mean_absolute_error(y_test, predicted_values)\n",
    "r2 = r2_score(y_test, predicted_values)\n",
    "adj_r2 = 1-(1-r2)*(n-1)/(n-k-1)\n",
    "\n",
    "print('RMSE =',RMSE, '\\nMSE =',MSE, '\\nMAE =',MAE, '\\nR2 =', r2, '\\nAdjusted R2 =', adj_r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete the end-point\n",
    "predictor.delete_model()\n",
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Retail Sales Forecast.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
